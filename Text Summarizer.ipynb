{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8c817d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from heapq import nlargest\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "11f2ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"text.txt\", 'r', encoding = \"utf8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "04fb325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(sample):\n",
    "    return re.sub(r'http\\S+', '', sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ca21fb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d2a90421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(text):\n",
    "    return re.sub(r'[^\\x00-\\x7f]', '', str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a6d244cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As people recognize the true value of data and try to get the most out of it, the demand for machine learning tools is increasing. But the complexity of the tasks involved in Machine learning can be overwhelming for non-ML experts, this is where Automated Machine Learning i.e., AutoML comes into the picture. AutoML can be used by non-ML experts for building ML projects. It can also be used by ML experts to perform repetitive tasks to save time and also accelerate machine learning research by automating models for regression and classification datasets and improving the efficiency of machine learning by selecting the best-suited model from the ones generated. Using AutoML, models can be trained and tuned without worrying about the hyperparameters, model architecture, or cross-validation strategies.[1][2]\\tIn a study in 2019, researchers estimated that training a very large deep learning model produces roughly 283950 kg of carbon dioxide, which equals the lifetime emission of five cars [18]. Although this number depends on various factors such as training time, the hardware used, etc. Imagine if each time a research team, a student organization, or a company wanted to train a model, it did so from scratch. This would lead to huge, unnecessary global costs! Basically, the point is deep learning models have a very high carbon footprint. This paper reduces the carbon footprint by predicting which candidate model would be the best fit for the given dataset instead of training all the candidate models, therefore, reducing the time of training multiple models as well as the carbon dioxide emission. \\tTo understand natural language, machines have to use complex data processing and state-of-the-art machine learning algorithms. These algorithms may differ depending upon the language and the type of data. It is also important to decide which machine learning methods should be applied based on the dataset and the task to be performed. Selecting the right method may become difficult as more accurate methods are constantly being developed. Also, the entire process might be different for different languages. Even after considering all these factors for choosing the algorithms and methods, getting the best results is not assured. AutoML for natural language processing (AutoNLP) can be used to address all these challenges. AutoNLP can be defined as an algorithm that can find the pipeline, features, and model that will give the best results for a given dataset. Using the concepts of AutoML, AutoNLP helps in automating the process of exploratory data analysis and creating fully functional NLP models. [3]It is tedious to find the best model and best set of hyperparameters for a given dataset even for experts. These tasks require a lot of time and resources since training a model on a given dataset may take hours or even days depending on the size of the dataset and the model being used and then changing hyperparameters and training the dataset all over again becomes an even more tedious and patience-testing task. Our goal is to reduce this time and effort and give the user the best model for an NLP classification task.This paper presents a model for AutoNLP which when given a dataset as an input gives the trained model, its accuracy, and the time required for training as the output. We have created a system to efficiently predict the best model for a given dataset and a set of models the user wants to consider. Our program is such that it is extremely easy to add transformer models to the pre-existing pool of models. Due to computational limitations, we have performed all experiments on Naive Bayes, BERT, Albert, and XLNet for binary and multi-class classification using multiple hyperparameter combinations for each. Users can easily append additional transformer models for the system to consider those models in addition to the existing ones. The goal of the application is to give the best model with optimized hyperparameters as the output for the given input dataset which can then be chosen according to the time taken or the accuracy achieved or a balance of both. '"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_keyword = remove_html(text)\n",
    "extract_keyword = remove_non_ascii(extract_keyword)\n",
    "extract_keyword = remove_URL(extract_keyword)\n",
    "extract_keyword.replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "33aa9d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake\n",
    "rk=Rake()\n",
    "rk.extract_keywords_from_text(extract_keyword)\n",
    "extract_keyword=rk.get_ranked_phrases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4db5c4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It can also be used by ML experts to perform repetitive tasks to save time and also accelerate machine learning research by automating models for regression and classification datasets and improving the efficiency of machine learning by selecting the best-suited model from the ones generated. These tasks require a lot of time and resources since training a model on a given dataset may take hours or even days depending on the size of the dataset and the model being used and then changing hyperparameters and training the dataset all over again becomes an even more tedious and patience-testing task. But the complexity of the tasks involved in Machine learning can be overwhelming for non-ML experts, this is where Automated Machine Learning i.e., AutoML comes into the picture.'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nopuch=[char for char in extract_keyword if char not in string.punctuation]\n",
    "nopuch=\"\".join(nopuch)\n",
    "process_text=[word for word in nopuch.split() if word.lower() not in nltk.corpus.stopwords.words('english')]\n",
    "word_freq={}\n",
    "for word in process_text:\n",
    "    if word not in word_freq:\n",
    "        word_freq[word]=1\n",
    "    else:\n",
    "        word_freq[word]=word_freq[word]+1\n",
    "max_freq=max(word_freq.values())\n",
    "\n",
    "for word in word_freq.keys():\n",
    "    word_freq[word]=(word_freq[word]/max_freq)\n",
    "sent_list=nltk.sent_tokenize(text)\n",
    "sent_score={}\n",
    "for sent in sent_list:\n",
    "    for word in nltk.word_tokenize(sent.lower()):\n",
    "        if word in word_freq.keys():\n",
    "            if sent not in sent_score.keys():\n",
    "                sent_score[sent]=word_freq[word]\n",
    "            else:\n",
    "                sent_score[sent]=sent_score[sent]+word_freq[word]\n",
    "summary_sent=nlargest(3,sent_score, key=sent_score.get)\n",
    "\n",
    "summary=\" \".join(summary_sent)\n",
    "\n",
    "summary.replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ce8b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
